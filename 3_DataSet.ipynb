{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. DataSet",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPZrjX5vFwwUmdfldRswCPx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iskra3138/ImageSr/blob/master/3_DataSet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bu8xxiSBOVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekIoYkbefOWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQDv63u_3Ku-",
        "colab_type": "text"
      },
      "source": [
        "### TFRecord 활용하여 DataSet 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNegY3FQBQXb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CLASSES = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGIOYhjZBQUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# TFRecord Parsing을 위한 함수 정의  \n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "IMG_WIDTH = 224\n",
        "IMG_HEIGHT = 224\n",
        "IMAGE_SIZE =  [IMG_HEIGHT, IMG_WIDTH]\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "## 본 실험에서는 16개의 tfrecord파일을 train/validation용으로 나눠서 사용합니다.\n",
        "## train전용, validation전용 tfrecord 파일들이 있으면 특정해서 list 로 넘기시면 됩니다.\n",
        "BUCKET = \"gs://iskra3138_share\"\n",
        "gcs_pattern = os.path.join(BUCKET, '*.tfrec')\n",
        "validation_split = 0.19\n",
        "filenames = tf.io.gfile.glob(gcs_pattern)\n",
        "split = len(filenames) - int(len(filenames) * validation_split)\n",
        "train_fns = filenames[:split]\n",
        "validation_fns = filenames[split:]\n",
        "\n",
        "## TFRecord Parsing 함수 (TFRecord 생성함수를 참고해서 만들어줍니다.)\n",
        "def parse_tfrecord(example):\n",
        "    features = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string),  # tf.string = bytestring (not text string)\n",
        "        \"file_name\": tf.io.FixedLenFeature([], tf.string),  # one bytestring\n",
        "        \"label_name\": tf.io.FixedLenFeature([], tf.string),  # one bytestring\n",
        "        \"label\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means scalar, one integer\n",
        "    }\n",
        "    # decode the TFRecord\n",
        "    example = tf.io.parse_single_example(example, features)\n",
        "    \n",
        "    \n",
        "    label = example['label']\n",
        "    label = tf.one_hot(indices=label, depth=5)   \n",
        "    image = tf.image.decode_jpeg(example['image'], channels=3)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32) ## make [0,255] to [0,1) resize 앞에 위치할 때만 [0,1), 즉 input이 float32가 아니어야 작동\n",
        "    image = tf.image.resize(image, IMAGE_SIZE) ## method가 tf.image.ResizeMethod.NEAREST_NEIGHBOR 가 아니면 출력은 무조건 float32\n",
        "    \n",
        "    file_name  = example['file_name']\n",
        "    label_name  = example['label_name']\n",
        "    \n",
        "    return image, label, file_name, label_name\n",
        "\n",
        "def load_dataset(filenames):\n",
        "  # Read from TFRecords. For optimal performance, we interleave reads from multiple files.\n",
        "  records = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
        "  return records.map(parse_tfrecord, num_parallel_calls=AUTO)\n",
        "\n",
        "def get_training_dataset():\n",
        "  dataset = load_dataset(train_fns)\n",
        "\n",
        "  # Create some additional training images by randomly flipping and\n",
        "  # increasing/decreasing the saturation of images in the training set. \n",
        "  def data_augment(image, label, file_name, label_name):\n",
        "    modified = tf.image.random_flip_left_right(image)\n",
        "    modified = tf.image.random_flip_up_down(modified)\n",
        "    return modified, label, file_name, label_name\n",
        "  augmented = dataset.map(data_augment, num_parallel_calls=AUTO)\n",
        "\n",
        "  # Prefetch the next batch while training (autotune prefetch buffer size).\n",
        "  return augmented.repeat().shuffle(2048).batch(batch_size).prefetch(AUTO) \n",
        "\n",
        "training_dataset = get_training_dataset()\n",
        "validation_dataset = load_dataset(validation_fns).batch(batch_size).prefetch(AUTO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J9m6MIOcR0h",
        "colab_type": "text"
      },
      "source": [
        "위 코드를 실행시키면, training_dataset, validation_dataset 모두 (image, label, file_name, label_name)구조로 element들이 구성됨\n",
        "\n",
        "training_dataset은 \n",
        "- augmented = dataset.map(data_augment, num_parallel_calls=AUTO)에서 랜덤으로 좌우플립/상하플립이 적용되고, \n",
        "- augmented.repeat().shuffle(2048).batch(batch_size).prefetch(AUTO) 에서 무한 반복으로, 섞고, batch_size만큼 생성됨\n",
        "\n",
        "validation_dataset은 \n",
        "- batch_size만큼 뽑히는 데, 전체 element들이 다 뽑히면 끝남"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_qIfsQ73RsL",
        "colab_type": "text"
      },
      "source": [
        "### TFrecord 파일 속에 있는 데이터들 개수 세기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDd47OjnBQSI",
        "colab_type": "code",
        "outputId": "68735438-da4d-41e4-c915-ee2f662bd5d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "## tfrecord 파일 내 데이터 개수 세기\n",
        "#### tfrecord 이름이 아니라 직접 데이터 개수를 확인하고 싶다면 아래 코드 실행\n",
        "#sum([1 for _ in tf.data.TFRecordDataset({TFRecord 파일 이름})])\n",
        "sum([1 for _ in tf.data.TFRecordDataset(filenames[0])])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "230"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJcmn9vfXWnT",
        "colab_type": "code",
        "outputId": "327e30bc-5b8d-494f-8b08-92c03d84634b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "## tfrecord 파일 내 데이터 개수 세기\n",
        "#### tfrecord 이름이 아니라 직접 데이터 개수를 확인하고 싶다면 아래 코드 실행\n",
        "#### 여러 개의 tfrecord를 list로 넘겨도 됨\n",
        "\n",
        "#sum([1 for _ in tf.data.TFRecordDataset([TFRecord 파일 리스트])])\n",
        "sum([1 for _ in tf.data.TFRecordDataset(filenames[0:3])])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "690"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_5BHOMJdW1c",
        "colab_type": "code",
        "outputId": "c5258b5e-7f49-4c89-baa0-00376998918e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "## train_fns list로 traind_data 개수 세기\n",
        "print (train_fns)\n",
        "print (sum([1 for _ in tf.data.TFRecordDataset(train_fns)]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['gs://iskra3138_share/00-230.tfrec', 'gs://iskra3138_share/01-230.tfrec', 'gs://iskra3138_share/02-230.tfrec', 'gs://iskra3138_share/03-230.tfrec', 'gs://iskra3138_share/04-230.tfrec', 'gs://iskra3138_share/05-230.tfrec', 'gs://iskra3138_share/06-230.tfrec', 'gs://iskra3138_share/07-230.tfrec', 'gs://iskra3138_share/08-230.tfrec', 'gs://iskra3138_share/09-230.tfrec', 'gs://iskra3138_share/10-230.tfrec', 'gs://iskra3138_share/11-230.tfrec', 'gs://iskra3138_share/12-230.tfrec']\n",
            "2990\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7D8TS0odWxA",
        "colab_type": "code",
        "outputId": "6221fe60-bbe8-4c23-ae53-475a2919847c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "## validation_fns list로 traind_data 개수 세기\n",
        "print (validation_fns)\n",
        "print (sum([1 for _ in tf.data.TFRecordDataset(validation_fns)]))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['gs://iskra3138_share/13-230.tfrec', 'gs://iskra3138_share/14-230.tfrec', 'gs://iskra3138_share/15-220.tfrec']\n",
            "680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA2I8cJcdwBy",
        "colab_type": "text"
      },
      "source": [
        "train data는 2990장, validation data는 680장임"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L44MZqs23Wh_",
        "colab_type": "text"
      },
      "source": [
        "### 1batch 데이터 n 개 추출하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72xqsmsqeHXP",
        "colab_type": "code",
        "outputId": "8a945356-dc67-4f5e-8219-48a7e35f37b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "## dataset 랜덤으로 1batch 데이터 뽑기 1\n",
        "## as_numpy_iterator()를 써서 next로 뽑기\n",
        "iter = validation_dataset.as_numpy_iterator()\n",
        "img, label, file_name, label_name = next(iter)\n",
        "label1 = label\n",
        "print (label1.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkJIG2PLx8SQ",
        "colab_type": "code",
        "outputId": "bf6a6204-1718-438a-8398-4a57dd76adc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# as_numpy_iterator()의 출력을 numpy array\n",
        "type(label1)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PBREmm-es9G",
        "colab_type": "code",
        "outputId": "5dd81e10-4745-4bbc-abfd-a07b4a05a137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "## dataset 랜덤으로 1batch 데이터 뽑기 2\n",
        "### dataset 자체를 쓰되, break\n",
        "### break를 쓰지 않으면 as_numpy_iterator()를 for문으로 돌릴때처럼 전체 데이터셋에 대해 한 바퀴 돔\n",
        "for img, label, file_name, label_name in validation_dataset :\n",
        "  label2 = label\n",
        "  break\n",
        "print (label2.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBdD0DjYes5S",
        "colab_type": "code",
        "outputId": "9f515212-3d9f-4f90-900e-1982b0ec31e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# take()의 출력을 EagerTensor\n",
        "type(label2)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.framework.ops.EagerTensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9m9gIeNnDHS7",
        "colab_type": "code",
        "outputId": "88168559-499e-457a-eedf-b6030c376528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "## dataset 랜덤으로 1batch 데이터 뽑기 3\n",
        "### take() 사용\n",
        "### take(n)을 쓰면 사전에 정의된 배치사이즈 크기의 데이터를 n번 샘플링 해옴\n",
        "for img, label, file_name, label_name in validation_dataset.take(1):\n",
        "  label3 = label\n",
        "  print (label3.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wbsvb1F2x2h0",
        "colab_type": "code",
        "outputId": "0ae619d7-93d0-4648-fe4a-cd4bb9ee24e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# take()의 출력을 EagerTensor\n",
        "type(label3)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.framework.ops.EagerTensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9bMytHLyimT",
        "colab_type": "code",
        "outputId": "89bbfef0-8db6-4034-9e3a-e802d5725989",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# 순서가 명시된 Dataset 정의\n",
        "# (0,10), (1, 11), ..., (9, 19) 형태의 DataSet을 만듦\n",
        "a = np.arange(10)\n",
        "b = np.arange(10, 20)\n",
        "print (a)\n",
        "print (b)\n",
        "range_dataset = tf.data.Dataset.from_tensor_slices((a, b))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 5 6 7 8 9]\n",
            "[10 11 12 13 14 15 16 17 18 19]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2WkGOHEzXva",
        "colab_type": "code",
        "outputId": "f197e75d-a298-4649-a99c-b7ada3133590",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "## dataset 랜덤으로 1batch 데이터 뽑기 1\n",
        "## as_numpy_iterator()를 써서 next로 뽑기\n",
        "iter = range_dataset.as_numpy_iterator()\n",
        "for i in range(10):\n",
        "  data = next(iter)\n",
        "  print (data)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, 10)\n",
            "(1, 11)\n",
            "(2, 12)\n",
            "(3, 13)\n",
            "(4, 14)\n",
            "(5, 15)\n",
            "(6, 16)\n",
            "(7, 17)\n",
            "(8, 18)\n",
            "(9, 19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEtvrc6dzJnx",
        "colab_type": "code",
        "outputId": "dfe17448-e432-4dcf-de40-cc3e9a4b4c24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "## dataset 랜덤으로 1batch 데이터 뽑기 2\n",
        "### take() 사용\n",
        "### 출력값은 EagerTensor의 Tuple이므로 출력 결과 중 numpy= 다음의 값을 보면 됨\n",
        "for data in range_dataset.take(1):\n",
        "  print (data)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(), dtype=int64, numpy=0>, <tf.Tensor: shape=(), dtype=int64, numpy=10>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OZoEK39zXsQ",
        "colab_type": "code",
        "outputId": "2d68d949-9269-4778-be6c-2b05e74596c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "## dataset 랜덤으로 1batch 데이터 뽑기 2\n",
        "### take() 사용시 numpy 값을 뽑고 싶다면 요소별로 변수로 받은 다음 numpy() 하면 됨\n",
        "\n",
        "for data1, data2 in range_dataset.take(10):\n",
        "  print (data1.numpy(), data2.numpy())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 10\n",
            "1 11\n",
            "2 12\n",
            "3 13\n",
            "4 14\n",
            "5 15\n",
            "6 16\n",
            "7 17\n",
            "8 18\n",
            "9 19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH3kesH01Axp",
        "colab_type": "code",
        "outputId": "ab53e325-074e-4cf0-c0e1-6e7e24adeb29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "## as_numpy_iterator()를 정의해서 사용할 때 1epoch이 넘어가서도 호출하면 error 발생\n",
        "iter = range_dataset.as_numpy_iterator()\n",
        "for i in range(11): ## data의 개수 10개를 넘어가면 error 발생\n",
        "  data = next(iter)\n",
        "  print (data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, 10)\n",
            "(1, 11)\n",
            "(2, 12)\n",
            "(3, 13)\n",
            "(4, 14)\n",
            "(5, 15)\n",
            "(6, 16)\n",
            "(7, 17)\n",
            "(8, 18)\n",
            "(9, 19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ird9aX9A1Awk",
        "colab_type": "code",
        "outputId": "f84a2ff7-ef65-41ec-d814-ad258fadd0f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "## take()를 사용하면 10개를 넘어가도 작동함, 10개에서 작동이 정지\n",
        "\n",
        "for data1, data2 in range_dataset.take(20):\n",
        "  print (data1.numpy(), data2.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 10\n",
            "1 11\n",
            "2 12\n",
            "3 13\n",
            "4 14\n",
            "5 15\n",
            "6 16\n",
            "7 17\n",
            "8 18\n",
            "9 19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEmoB2--3sHf",
        "colab_type": "text"
      },
      "source": [
        "###  DataSet 내에 있는 모든 데이터를 한번씩만 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukXBDo2ugBId",
        "colab_type": "code",
        "outputId": "8d0d90cd-21ae-4c64-d969-116a9df5e068",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# TFRecord Data Set으로 재실험\n",
        "## as_numpy_iterator()를 쓰면 딱 1epoch만큼 샘플링할 수 있음\n",
        "## 64 batch씩 10번 남은 40batch 1번, 총 11번 반복함\n",
        "num_samples = 0\n",
        "for img, label, file_name, label_name in validation_dataset.as_numpy_iterator():\n",
        "  num_samples += label.shape[0]\n",
        "print (num_samples)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u8MU6uiigiOP"
      },
      "source": [
        "전체 데이터 개수와 똑같아졌음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOexvF0RgVK6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "07c19f38-f80b-47de-830f-d78ecce70db0"
      },
      "source": [
        "# TFRecord Data Set으로 재실험\n",
        "## dataset  자체를 써도 딱 1epoch만큼 샘플링할 수 있음 (차이는 아웃풋이 Tensor임)\n",
        "## 64 batch씩 10번 남은 40batch 1번, 총 11번 반복함\n",
        "num_samples = 0\n",
        "for img, label, file_name, label_name in validation_dataset:\n",
        "  num_samples += label.shape[0]\n",
        "print (num_samples)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3cZnl8CgzBm",
        "colab_type": "text"
      },
      "source": [
        "전체 데이터 개수와 똑같아졌음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze39cenXgWLk",
        "colab_type": "code",
        "outputId": "a0747920-bf97-4eea-ae91-21ec8b569c73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "## take(n)를 쓰면 계속해서 증가하다가 1epoch 샘플링에서 끝남\n",
        "for n in range(15) :\n",
        "  num_samples = 0\n",
        "  for img, label, file_name, label_name in validation_dataset.take(n):\n",
        "    num_samples += label.shape[0]\n",
        "  print (n, num_samples)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0\n",
            "1 64\n",
            "2 128\n",
            "3 192\n",
            "4 256\n",
            "5 320\n",
            "6 384\n",
            "7 448\n",
            "8 512\n",
            "9 576\n",
            "10 640\n",
            "11 680\n",
            "12 680\n",
            "13 680\n",
            "14 680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIoqFiCYhkMS",
        "colab_type": "text"
      },
      "source": [
        "계속해서 64개씩 늘어나다 11번째는 남은 40만큼 늘어나고 그 이후는 변화가 없음"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqH-djRH30mf",
        "colab_type": "text"
      },
      "source": [
        "### 여러 Class가 섞여 있는 DataSet에서 Class 별 DataSet 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U58DiBQMDHNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class별 데이터세트 만들기\n",
        "## 원하는 클래스끼리만 모아 놓고 싶을 때는 fliter를 적용하면 됨\n",
        "### label이 1인 데이터세트를 만드는 예제\n",
        "\n",
        "def select_label1 (img, label, file_name, label_name):\n",
        "  return tf.math.equal(tf.argmax(label), 1) ## label이 one-hot 형태임\n",
        "\n",
        "label1dataset = validation_dataset.unbatch().filter(select_label1) ## 한 장씩 평가해야 해서 unbatch 해줌"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ftcVWPTBH3C",
        "colab_type": "code",
        "outputId": "48caaf21-74a2-41af-fb02-6581208cea16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for img, label, file_name, label_name in label1dataset.as_numpy_iterator():\n",
        "  print (label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSBXuTc3ioj_",
        "colab_type": "code",
        "outputId": "5665c4e1-28a0-4566-9959-c6a33aa48497",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "label.numpy().shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XakRBCkSipQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}